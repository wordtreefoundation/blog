<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[The WordTree Foundation]]></title><description><![CDATA[The WordTree Foundation studies the relationships between books, with a special interest in LDS scripture such as the Book of Mormon.]]></description><link>http://blog.wordtree.org</link><generator>RSS for Node</generator><lastBuildDate>Mon, 05 Mar 2018 04:11:10 GMT</lastBuildDate><item><title><![CDATA[Site Update]]></title><description><![CDATA[After 3 years of quietude, we've updated the website to make it easier for you to see what WordTree is working on, to find what you're looking for, and to contribute to projects you find interesting.]]></description><link>http://blog.wordtree.org/articles/site-update</link><guid isPermaLink="false">http://blog.wordtree.org/articles/site-update</guid><pubDate>Sun, 04 Mar 2018 19:59:15 GMT</pubDate><content:encoded>&lt;p&gt;We’ve updated the website!&lt;/p&gt;
&lt;p&gt;Previously, we had a blog (that was starting to get a bit crusty…) hosted at (wordtree.org)[http://wordtree.org] and for several years now, we’ve been wanting to do a bit more with the website.&lt;/p&gt;
&lt;p&gt;First of all, we want to showcase some of the things we’ve done in the past, and make it easier to access the information and resources that WordTree provides. In particular, we’ve highlighted 3 of the things we’ve done that we think might be useful to you:&lt;/p&gt;
&lt;div style=&quot;padding-left: 4.5em&quot;&gt;
&lt;h3&gt;&lt;a href=&quot;https://www.bookofmormonorigins.com&quot;&gt;Book of Mormon Origins&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An open-source, public domain resource that adds missing footnotes to the Book of Mormon.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://wordtreefoundation.github.io/thelatewar/&quot;&gt;The Late War Study&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A computer-aided study that reveals some remarkable similarities between the Book of Mormon and The Late War Between the United States and Great Britain (published in 1816).&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;https://github.com/wordtreefoundation/bomdb&quot;&gt;BomDB&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A resource for computer-aided studies of the Book of Mormon. Contains a command-line tool (Linux/MacOS/Windows) that can be used to find specific verses across multiple editions, or produce full copies (with our without chapter/verse annotations) of each edition.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Second, we’re changing the site around so that the blog is not the only thing visible. We’ll be working on providing APIs, data, and new and interesting information about the Book of Mormon. We’ll highlight some of these as they become ready.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[DIY Mosiah Priority with BomDB]]></title><description><![CDATA[We recently created BomDB as a tool for Book of Mormon researchers. This post shows how to use it to replicate some of the analysis that led to the Mosiah Priority hypothesis. This is especially for you if you like to do-it-yourself for the sake of skeptical inquiry.]]></description><link>http://blog.wordtree.org/articles/diy-mosiah-priority</link><guid isPermaLink="false">http://blog.wordtree.org/articles/diy-mosiah-priority</guid><pubDate>Fri, 17 Apr 2015 22:35:19 GMT</pubDate><content:encoded>&lt;p&gt;We recently created &lt;a href=&quot;https://github.com/wordtreefoundation/bomdb&quot;&gt;BomDB&lt;/a&gt; as a tool for Book of Mormon researchers. This post shows how to use it to replicate some of the analysis that led to the Mosiah Priority hypothesis. This is especially for you if you like to do-it-yourself for the sake of skeptical inquiry.&lt;/p&gt;
&lt;p&gt;Brent Metcalfe wrote a seminal chapter of New Approaches to the Book of Mormon in 1993 called &lt;a href=&quot;http://signaturebookslibrary.org/new-approaches-to-the-book-of-mormon-10/&quot;&gt;The Priority of Mosiah&lt;/a&gt;. In it, he convincingly shows that Mosiah was written &lt;em&gt;first&lt;/em&gt;, prior to 1st Nephi, and one of the techniques used was a simple wordcount of the occurrences of “wherefore” and “therefore” throughout the Book of Mormon.&lt;/p&gt;
&lt;p&gt;We can use &lt;a href=&quot;https://github.com/wordtreefoundation/bomdb&quot;&gt;BomDB&lt;/a&gt; (a command-line tool and Ruby gem that contains several editions of the Book of Mormon) to replicate Metcalfe’s work and even further it.&lt;/p&gt;
&lt;p&gt;First, let’s get some raw data to work with. We’ll count up the number of “wherefore” and “therefore” occurrences in each book of the Book of Mormon, and print it out as text:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;require &apos;bomdb&apos; # version 0.6.2
require &apos;json&apos;

q = BomDB::Query.new(exclude: &apos;Bible&apos;)

data = q.books.map do |book, content|
  wordcount = content.scan(/ +/).size
  wh = content.scan(/wherefore/i).size.to_f / wordcount
  th = content.scan(/therefore/i).size.to_f / wordcount
  [book, wh, th]
end

labels, wherefores, therefores = data.transpose
puts &quot;Labels: #{labels.to_json}&quot;
puts &quot;Wherefores: #{wherefores.to_json}&quot;
puts &quot;Therefores: #{wherefores.to_json}&quot;&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Note that the &lt;code&gt;BomDB::Query&lt;/code&gt; above handily excludes Biblical chapters and verses from our analysis using &lt;code&gt;exclude: &apos;Bible-OT&apos;&lt;/code&gt;. Next, we iterate over each book and divide the number of times we see ‘wherefore’ by the total number of words in the book (e.g. 1 Nephi). We do the same for ‘therefore’. Finally, &lt;code&gt;transpose&lt;/code&gt; takes our array-of-arrays and turns it back in to 3 arrays: the labels, the normalized ‘wherefore’ counts, and the normalized ‘therefore’ counts.&lt;/p&gt;
&lt;p&gt;Here’s what the output looks like:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Labels: [&quot;1 Nephi&quot;,&quot;2 Nephi&quot;,&quot;Jacob&quot;,&quot;Enos&quot;,
  &quot;Jarom&quot;,&quot;Omni&quot;,&quot;Words of Mormon&quot;,&quot;Mosiah&quot;,
  &quot;Alma&quot;,&quot;Helaman&quot;,&quot;3 Nephi&quot;,&quot;4 Nephi&quot;,&quot;Mormon&quot;,
  &quot;Ether&quot;,&quot;Moroni&quot;]
Wherefores: [0.00426,0.00705,0.00581,0.00515,0.00411,0.00429,
  0.00579,0.0,4.0e-05,0.0,0.00012,0.0,0.0,0.00378,0.00627]
Therefores: [0.00426,0.00705,0.00581,0.00515,0.00411,0.00429,
  0.00579,0.0,4.0e-05,0.0,0.00012,0.0,0.0,0.00378,0.00627]&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;It would be easier to understand this data if we could chart it, so let’s do that using &lt;a href=&quot;http://www.highcharts.com/&quot;&gt;Highcharts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since we’ll be doing more than comparing ‘wherefore’ and ‘therefore’, let’s make a method that compares any number of words and their frequencies. Basically, this is a generalized version of the code above (note, this requires Ruby 2.1 or above):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;def compare_frequencies(words:, group_by: :books, range: nil)
  BomDB::Query.new(range: range, exclude: &apos;Bible-OT&apos;).
  send(group_by).map do |heading, content|
    wordcount = content.scan(/ +/).size
    frequencies = words.map do |word|
      content.scan(/\b#{word}\b/i).size.to_f / wordcount
    end
    [group_by == :chapters ? heading[1] : heading] + frequencies
  end.transpose
end&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Now, we can give it a set of words, and we get the same thing as above:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;compare_frequencies([&quot;wherefore&quot;, &quot;therefore&quot;])&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Additionally, we need a method that turns our data into a javascript chart using Highcharts:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;def make_chart(words:, group_by: :books, range: nil,
  title: &quot;Chart&quot;, subtitle: nil, labels: [], xtitle: nil, ytitle: nil,
  tooltip: &apos; occurrences per word&apos;, placeholder: &apos;PLACEHOLDER&apos;, height: 400)
  labels, *data = compare_frequencies(words: words, group_by: group_by, range: range)

  series = words.zip(data).map do |word, datapoints|
    { name: word, data: datapoints }
  end

  {
    chart: {
        renderTo: placeholder,
        height: height
    },
    title: {
        text: title,
        x: -20
    },
    subtitle: {
        text: subtitle,
        x: -20
    },
    xAxis: {
        categories: labels,
        title: {
            text: xtitle
        }
    },
    yAxis: {
        min: 0,
        title: {
            text: ytitle
        }
    },
    tooltip: {
        valueSuffix: tooltip
    },
    legend: {
        layout: &apos;vertical&apos;,
        align: &apos;right&apos;,
        verticalAlign: &apos;middle&apos;,
        borderWidth: 0
    },
    series: series
  }
end&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Lastly, a helper method to generate the embedded script tags for this blog:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;def script_chart(**args)
  &quot;&lt;script&gt;&quot; +
    &quot;var div = document.createElement(&apos;div&apos;), &quot; +
        &quot;script = document.scripts[document.scripts.length - 1]; &quot; +
    &quot;script.parentElement.insertBefore(div, script); &quot; +
    &quot;new Highcharts.Chart(&quot; + 
      make_chart(**args).to_json.gsub(&apos;&quot;PLACEHOLDER&quot;&apos;, &apos;div&apos;) +
    &quot;);&lt;/script&gt;&quot;
end&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;When we string this together,&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;puts script_chart(
  title: &quot;Wherefores &amp; Therefores Per Word&quot;,
  subtitle: &quot;in the Book of Mormon&quot;,
  xtitle: &quot;Books in the Book of Mormon&quot;,
  ytitle: &quot;Normalized Word Count&quot;,
  words: [&quot;wherefore&quot;, &quot;therefore&quot;]
)&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Here’s what we get:&lt;/p&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;Wherefores &amp; Therefores Per Word&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:&quot;in the Book of Mormon&quot;,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[&quot;1 Nephi&quot;,&quot;2 Nephi&quot;,&quot;Jacob&quot;,&quot;Enos&quot;,&quot;Jarom&quot;,&quot;Omni&quot;,&quot;Words of Mormon&quot;,&quot;Mosiah&quot;,&quot;Alma&quot;,&quot;Helaman&quot;,&quot;3 Nephi&quot;,&quot;4 Nephi&quot;,&quot;Mormon&quot;,&quot;Ether&quot;,&quot;Moroni&quot;],&quot;title&quot;:{&quot;text&quot;:&quot;Books in the Book of Mormon&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;wherefore&quot;,&quot;data&quot;:[{&quot;total&quot;:23570,&quot;count&quot;:101,&quot;y&quot;:0.004285108188375053},{&quot;total&quot;:18905,&quot;count&quot;:130,&quot;y&quot;:0.006876487701666226},{&quot;total&quot;:9125,&quot;count&quot;:53,&quot;y&quot;:0.005808219178082192},{&quot;total&quot;:1165,&quot;count&quot;:6,&quot;y&quot;:0.005150214592274678},{&quot;total&quot;:730,&quot;count&quot;:3,&quot;y&quot;:0.00410958904109589},{&quot;total&quot;:1398,&quot;count&quot;:6,&quot;y&quot;:0.004291845493562232},{&quot;total&quot;:864,&quot;count&quot;:5,&quot;y&quot;:0.005787037037037037},{&quot;total&quot;:30223,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:85236,&quot;count&quot;:3,&quot;y&quot;:3.519639588906096e-05},{&quot;total&quot;:20522,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:24538,&quot;count&quot;:1,&quot;y&quot;:4.0753117613497433e-05},{&quot;total&quot;:1947,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:9446,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:16678,&quot;count&quot;:63,&quot;y&quot;:0.0037774313466842546},{&quot;total&quot;:6117,&quot;count&quot;:38,&quot;y&quot;:0.006212195520680072}]},{&quot;name&quot;:&quot;therefore&quot;,&quot;data&quot;:[{&quot;total&quot;:23570,&quot;count&quot;:13,&quot;y&quot;:0.0005515485787017395},{&quot;total&quot;:18905,&quot;count&quot;:6,&quot;y&quot;:0.0003173763554615181},{&quot;total&quot;:9125,&quot;count&quot;:1,&quot;y&quot;:0.00010958904109589041},{&quot;total&quot;:1165,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:730,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1398,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:864,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:30223,&quot;count&quot;:122,&quot;y&quot;:0.004036660821228865},{&quot;total&quot;:85236,&quot;count&quot;:288,&quot;y&quot;:0.0033788540053498522},{&quot;total&quot;:20522,&quot;count&quot;:63,&quot;y&quot;:0.003069876230386902},{&quot;total&quot;:24538,&quot;count&quot;:85,&quot;y&quot;:0.003464014997147282},{&quot;total&quot;:1947,&quot;count&quot;:5,&quot;y&quot;:0.0025680534155110425},{&quot;total&quot;:9446,&quot;count&quot;:22,&quot;y&quot;:0.0023290281600677537},{&quot;total&quot;:16678,&quot;count&quot;:26,&quot;y&quot;:0.0015589399208538195},{&quot;total&quot;:6117,&quot;count&quot;:0,&quot;y&quot;:0.0}]}]});&lt;/script&gt;
&lt;p&gt;Ether is really interesting. It’s the only book that has a substantial number of ‘wherefores’ &lt;strong&gt;and&lt;/strong&gt; ‘therefores’. If the Book of Mormon had two or more authors, perhaps we would expect one author to be favoring ‘wherefore’, and another author favoring ‘therefore’, and so we would expect a clean break. On the other hand, if there is one author (i.e. Joseph Smith) whose vocabulary and word preference is changing over time, we’d expect a smooth transition.&lt;/p&gt;
&lt;p&gt;Using our &lt;code&gt;compare_frequencies&lt;/code&gt; method above, let’s generate a chart and zoom in on Ether:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;puts script_chart(
  range: &apos;Ether 1-15&apos;,
  group_by: :chapters,
  title: &quot;Wherefores &amp; Therefores Per Word in Ether&quot;,
  subtitle: &quot;in the Book of Mormon&quot;,
  xtitle: &quot;Chapters in Ether&quot;,
  ytitle: &quot;Normalized Word Count&quot;,
  words: [&quot;wherefore&quot;, &quot;therefore&quot;]
)&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Here’s what it looks like:&lt;/p&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;Wherefores &amp; Therefores Per Word in Ether&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:&quot;in the Book of Mormon&quot;,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],&quot;title&quot;:{&quot;text&quot;:&quot;Chapters in Ether&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;wherefore&quot;,&quot;data&quot;:[{&quot;total&quot;:903,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1373,&quot;count&quot;:2,&quot;y&quot;:0.0014566642388929353},{&quot;total&quot;:1257,&quot;count&quot;:3,&quot;y&quot;:0.002386634844868735},{&quot;total&quot;:888,&quot;count&quot;:2,&quot;y&quot;:0.0022522522522522522},{&quot;total&quot;:223,&quot;count&quot;:1,&quot;y&quot;:0.004484304932735426},{&quot;total&quot;:1048,&quot;count&quot;:1,&quot;y&quot;:0.0009541984732824427},{&quot;total&quot;:918,&quot;count&quot;:6,&quot;y&quot;:0.006535947712418301},{&quot;total&quot;:1228,&quot;count&quot;:6,&quot;y&quot;:0.004885993485342019},{&quot;total&quot;:1427,&quot;count&quot;:4,&quot;y&quot;:0.002803083391730904},{&quot;total&quot;:1418,&quot;count&quot;:6,&quot;y&quot;:0.004231311706629055},{&quot;total&quot;:763,&quot;count&quot;:2,&quot;y&quot;:0.002621231979030144},{&quot;total&quot;:1543,&quot;count&quot;:15,&quot;y&quot;:0.009721322099805573},{&quot;total&quot;:1226,&quot;count&quot;:6,&quot;y&quot;:0.004893964110929853},{&quot;total&quot;:1137,&quot;count&quot;:4,&quot;y&quot;:0.003518029903254178},{&quot;total&quot;:1312,&quot;count&quot;:5,&quot;y&quot;:0.0038109756097560975}]},{&quot;name&quot;:&quot;therefore&quot;,&quot;data&quot;:[{&quot;total&quot;:903,&quot;count&quot;:3,&quot;y&quot;:0.0033222591362126247},{&quot;total&quot;:1373,&quot;count&quot;:2,&quot;y&quot;:0.0014566642388929353},{&quot;total&quot;:1257,&quot;count&quot;:7,&quot;y&quot;:0.005568814638027049},{&quot;total&quot;:888,&quot;count&quot;:3,&quot;y&quot;:0.0033783783783783786},{&quot;total&quot;:223,&quot;count&quot;:1,&quot;y&quot;:0.004484304932735426},{&quot;total&quot;:1048,&quot;count&quot;:3,&quot;y&quot;:0.0028625954198473282},{&quot;total&quot;:918,&quot;count&quot;:1,&quot;y&quot;:0.0010893246187363835},{&quot;total&quot;:1228,&quot;count&quot;:1,&quot;y&quot;:0.0008143322475570033},{&quot;total&quot;:1427,&quot;count&quot;:3,&quot;y&quot;:0.002102312543798178},{&quot;total&quot;:1418,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:763,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1543,&quot;count&quot;:1,&quot;y&quot;:0.0006480881399870382},{&quot;total&quot;:1226,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1137,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1312,&quot;count&quot;:1,&quot;y&quot;:0.0007621951219512195}]}]});&lt;/script&gt;
&lt;p&gt;According to Metcalfe, Ether was dictated in late May 1829. It looks like this was the period of time when Joseph began preferring ‘wherefore’ over ‘therefore’. Indeed, if you look at the Book of Commandments, a similar pattern appears (see Metcalfe’s chapter).&lt;/p&gt;
&lt;p&gt;What about other words? Metcalfe mentions ‘whoso’ and ‘whosoever’. Let’s check these out:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;puts script_chart(
  title: &quot;Whosos &amp; Whosoevers Per Word&quot;,
  subtitle: &quot;in the Book of Mormon&quot;,
  xtitle: &quot;Books in the Book of Mormon&quot;,
  ytitle: &quot;Normalized Word Count&quot;,
  words: [&quot;whoso\\b&quot;, &quot;whosoever&quot;]
)&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;And the resulting chart:&lt;/p&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;Whosos &amp; Whosoevers Per Word&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:&quot;in the Book of Mormon&quot;,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[&quot;1 Nephi&quot;,&quot;2 Nephi&quot;,&quot;Jacob&quot;,&quot;Enos&quot;,&quot;Jarom&quot;,&quot;Omni&quot;,&quot;Words of Mormon&quot;,&quot;Mosiah&quot;,&quot;Alma&quot;,&quot;Helaman&quot;,&quot;3 Nephi&quot;,&quot;4 Nephi&quot;,&quot;Mormon&quot;,&quot;Ether&quot;,&quot;Moroni&quot;],&quot;title&quot;:{&quot;text&quot;:&quot;Books in the Book of Mormon&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;whoso&quot;,&quot;data&quot;:[{&quot;total&quot;:23570,&quot;count&quot;:5,&quot;y&quot;:0.00021213406873143826},{&quot;total&quot;:18905,&quot;count&quot;:3,&quot;y&quot;:0.00015868817773075905},{&quot;total&quot;:9125,&quot;count&quot;:1,&quot;y&quot;:0.00010958904109589041},{&quot;total&quot;:1165,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:730,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1398,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:864,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:30223,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:85236,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:20522,&quot;count&quot;:1,&quot;y&quot;:4.8728194133125426e-05},{&quot;total&quot;:24538,&quot;count&quot;:15,&quot;y&quot;:0.0006112967642024615},{&quot;total&quot;:1947,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:9446,&quot;count&quot;:3,&quot;y&quot;:0.0003175947491001482},{&quot;total&quot;:16678,&quot;count&quot;:11,&quot;y&quot;:0.0006595515049766159},{&quot;total&quot;:6117,&quot;count&quot;:2,&quot;y&quot;:0.00032695765898316167}]},{&quot;name&quot;:&quot;whosoever&quot;,&quot;data&quot;:[{&quot;total&quot;:23570,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:18905,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:9125,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1165,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:730,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1398,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:864,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:30223,&quot;count&quot;:21,&quot;y&quot;:0.0006948350593918538},{&quot;total&quot;:85236,&quot;count&quot;:30,&quot;y&quot;:0.0003519639588906096},{&quot;total&quot;:20522,&quot;count&quot;:9,&quot;y&quot;:0.00043855374719812884},{&quot;total&quot;:24538,&quot;count&quot;:5,&quot;y&quot;:0.00020376558806748716},{&quot;total&quot;:1947,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:9446,&quot;count&quot;:1,&quot;y&quot;:0.00010586491636671607},{&quot;total&quot;:16678,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:6117,&quot;count&quot;:0,&quot;y&quot;:0.0}]}]});&lt;/script&gt;
&lt;p&gt;Between 3rd Nephi and Mormon, a clear inversion occurs—whereas ‘whosoever’ was the most common synonym beginning in Mosiah, by Moroni, ‘whoso’ has completely taken its place, and the trend continues into 1st &amp;#x26; 2nd Nephi, as well as Jacob. If we took the hypothesis that 1st Nephi was authored before Mosiah, it would be hard to explain the prevalence of whoso, then its complete absence, then its return.&lt;/p&gt;
&lt;p&gt;Let’s take a look at 3rd Nephi by “zooming in”:&lt;/p&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;Whosos &amp; Whosoevers Per Word in 3rd Nephi&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:null,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[1,2,3,4,5,6,7,8,9,10,11,12,15,16,17,18,19,20,21,23,26,27,28,29,30],&quot;title&quot;:{&quot;text&quot;:&quot;Chapters in 3rd Nephi&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;whoso&quot;,&quot;data&quot;:[{&quot;total&quot;:1333,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:768,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1354,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1513,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:929,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1193,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1133,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:869,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:966,&quot;count&quot;:2,&quot;y&quot;:0.002070393374741201},{&quot;total&quot;:843,&quot;count&quot;:1,&quot;y&quot;:0.0011862396204033216},{&quot;total&quot;:1434,&quot;count&quot;:6,&quot;y&quot;:0.0041841004184100415},{&quot;total&quot;:397,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:727,&quot;count&quot;:1,&quot;y&quot;:0.001375515818431912},{&quot;total&quot;:829,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:871,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1346,&quot;count&quot;:2,&quot;y&quot;:0.0014858841010401188},{&quot;total&quot;:1229,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1371,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:956,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:414,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:779,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1285,&quot;count&quot;:2,&quot;y&quot;:0.0015564202334630351},{&quot;total&quot;:1450,&quot;count&quot;:1,&quot;y&quot;:0.000689655172413793},{&quot;total&quot;:396,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:129,&quot;count&quot;:0,&quot;y&quot;:0.0}]},{&quot;name&quot;:&quot;whosoever&quot;,&quot;data&quot;:[{&quot;total&quot;:1333,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:768,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1354,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1513,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:929,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1193,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1133,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:869,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:966,&quot;count&quot;:1,&quot;y&quot;:0.0010351966873706005},{&quot;total&quot;:843,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1434,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:397,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:727,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:829,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:871,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1346,&quot;count&quot;:1,&quot;y&quot;:0.0007429420505200594},{&quot;total&quot;:1229,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1371,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:956,&quot;count&quot;:2,&quot;y&quot;:0.0020920502092050207},{&quot;total&quot;:414,&quot;count&quot;:1,&quot;y&quot;:0.0024154589371980675},{&quot;total&quot;:779,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1285,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1450,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:396,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:129,&quot;count&quot;:0,&quot;y&quot;:0.0}]}]});&lt;/script&gt;
&lt;p&gt;There’s no clear trend-line up or down. Many of these verses are taken from the New Testament, where the language of Jesus is borrowed. It’s interesting to see that in the Book of Mormon, Jesus uses ‘whoso’ and ‘whosoever’ interchangeably:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;bomdb show --search &apos;whoso&apos; &apos;3 Nephi 1-30&apos;&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;&lt;span style=&quot;color:#9fa01c&quot;&gt;3 Nephi&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;
&lt;/span&gt;&lt;span style=&quot;color:#2fb41d&quot;&gt;9&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;:&lt;/span&gt;&lt;span style=&quot;color:#2fe71a&quot;&gt;14&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;
Yea, verily I say unto you: If ye will come unto me, ye shall have
eternal life. Behold, mine arm of mercy is extended towards you. And
&lt;/span&gt;&lt;span style=&quot;color:#b42419;font-weight:bold&quot;&gt;whoso&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;ever
will come, him will I receive. And blessed are they which cometh unto
me.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color:#9fa01c&quot;&gt;3 Nephi&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;
&lt;/span&gt;&lt;span style=&quot;color:#2fb41d&quot;&gt;9&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;:&lt;/span&gt;&lt;span style=&quot;color:#2fe71a&quot;&gt;20&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;
And ye shall offer for a sacrifice unto me a broken heart and a
contrite spirit. And &lt;/span&gt;&lt;span style=&quot;color:#b42419;font-weight:bold&quot;&gt;whoso&lt;/span&gt;&lt;span style=&quot;color:#050505&quot;&gt;
cometh unto me with a broken heart and a contrite spirit, him will I
baptize with fire and with the Holy Ghost, even as the Lamanites
because of their faith in me at the time of their conversion were
baptized with fire and with the Holy Ghost--and they knew it not.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I will spare you the 29 verses in 3rd Nephi that mention “whoso”, but if you’d like to see all references, by all means run the command above.&lt;/p&gt;
&lt;p&gt;What about Mormon?&lt;/p&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;Whosos &amp; Whosoevers Per Word in Mormon&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:null,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[1,2,3,4,5,6,7,8,9],&quot;title&quot;:{&quot;text&quot;:&quot;Chapters in Mormon&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;whoso&quot;,&quot;data&quot;:[{&quot;total&quot;:704,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1262,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:938,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:823,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1067,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:908,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:451,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1719,&quot;count&quot;:2,&quot;y&quot;:0.0011634671320535194},{&quot;total&quot;:1566,&quot;count&quot;:1,&quot;y&quot;:0.0006385696040868455}]},{&quot;name&quot;:&quot;whosoever&quot;,&quot;data&quot;:[{&quot;total&quot;:704,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1262,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:938,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:823,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1067,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:908,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:451,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1719,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1566,&quot;count&quot;:1,&quot;y&quot;:0.0006385696040868455}]}]});&lt;/script&gt;
&lt;p&gt;There are 2 ‘whoso’s in chapter 8, and 1 ‘whoso’ and 1 ‘whosoever’ in chapter 9. These occur when Moroni begins speaking.&lt;/p&gt;
&lt;p&gt;Here’s another interesting one we found. Searching for occurrences of ‘House of Israel’, the Book of Mormon distributes them in a similar fashion as ‘wherefore’ and ‘whoso’:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-ruby&quot;&gt;&lt;code class=&quot;language-language-ruby&quot;&gt;puts script_chart(
  title: &quot;&apos;House of Israel&apos; Per Word&quot;,
  subtitle: &quot;in the Book of Mormon&quot;,
  xtitle: &quot;Books in the Book of Mormon&quot;,
  ytitle: &quot;Normalized Word Count&quot;,
  words: [&quot;house of israel&quot;]
)&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;script&gt;var div = document.createElement(&apos;div&apos;), script = document.scripts[document.scripts.length - 1]; script.parentElement.insertBefore(div, script); new Highcharts.Chart({&quot;chart&quot;:{&quot;renderTo&quot;:div,&quot;height&quot;:400},&quot;title&quot;:{&quot;text&quot;:&quot;&apos;House of Israel&apos; Per Word&quot;,&quot;x&quot;:-20},&quot;subtitle&quot;:{&quot;text&quot;:&quot;in the Book of Mormon&quot;,&quot;x&quot;:-20},&quot;xAxis&quot;:{&quot;categories&quot;:[&quot;1 Nephi&quot;,&quot;2 Nephi&quot;,&quot;Jacob&quot;,&quot;Enos&quot;,&quot;Jarom&quot;,&quot;Omni&quot;,&quot;Words of Mormon&quot;,&quot;Mosiah&quot;,&quot;Alma&quot;,&quot;Helaman&quot;,&quot;3 Nephi&quot;,&quot;4 Nephi&quot;,&quot;Mormon&quot;,&quot;Ether&quot;,&quot;Moroni&quot;],&quot;title&quot;:{&quot;text&quot;:&quot;Books in the Book of Mormon&quot;}},&quot;yAxis&quot;:{&quot;min&quot;:0,&quot;title&quot;:{&quot;text&quot;:&quot;Normalized Word Count&quot;}},&quot;tooltip&quot;:{&quot;formatter&quot;:function() { return &quot;&quot; + this.point.count + &quot; occurrences / &quot; + this.point.total + &quot; total words&quot; }},&quot;legend&quot;:{&quot;layout&quot;:&quot;vertical&quot;,&quot;align&quot;:&quot;right&quot;,&quot;verticalAlign&quot;:&quot;middle&quot;,&quot;borderWidth&quot;:0},&quot;series&quot;:[{&quot;name&quot;:&quot;house of israel&quot;,&quot;data&quot;:[{&quot;total&quot;:23570,&quot;count&quot;:35,&quot;y&quot;:0.001484938481120068},{&quot;total&quot;:18905,&quot;count&quot;:19,&quot;y&quot;:0.0010050251256281408},{&quot;total&quot;:9125,&quot;count&quot;:5,&quot;y&quot;:0.000547945205479452},{&quot;total&quot;:1165,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:730,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:1398,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:864,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:30223,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:85236,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:20522,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:24538,&quot;count&quot;:37,&quot;y&quot;:0.001507865351699405},{&quot;total&quot;:1947,&quot;count&quot;:0,&quot;y&quot;:0.0},{&quot;total&quot;:9446,&quot;count&quot;:11,&quot;y&quot;:0.0011645140800338768},{&quot;total&quot;:16678,&quot;count&quot;:5,&quot;y&quot;:0.0002997961386257345},{&quot;total&quot;:6117,&quot;count&quot;:1,&quot;y&quot;:0.00016347882949158083}]}]});&lt;/script&gt;
&lt;p&gt;Here again, it looks like the phrase “House of Israel” was first encountered in 3rd Nephi, and then favored through Moroni, 1st and 2nd Nephi, and finally Jacob. Its absence from Enos to Helaman is hard to explain without a dictation order that starts somewhere after Jacob and before 3rd Nephi.&lt;/p&gt;
&lt;p&gt;If you have ideas to test, or want to replicate this work, give &lt;a href=&quot;https://github.com/wordtreefoundation/bomdb&quot;&gt;BomDB&lt;/a&gt; a try!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; 2015-04-18: These charts were including data from verses in 3 Nephi that were borrowed from the New Testament (ch. 12, 13, 14). Those data points have now been fixed.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Using TextGrams.jl]]></title><description><![CDATA[A rundown of the use of TextGrams.jl, a library used to score the relatedness of 2 or more books based on the similarity of their ngrams.]]></description><link>http://blog.wordtree.org/articles/using-textgrams-jl</link><guid isPermaLink="false">http://blog.wordtree.org/articles/using-textgrams-jl</guid><pubDate>Sun, 29 Mar 2015 16:53:58 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://github.com/wordtreefoundation/TextGrams.jl&quot;&gt;TextGrams.jl&lt;/a&gt; is a library that we use to score the relatedness of 2 or more books based on their ngrams (i.e. phrases made up of “N” words in a row, where a useful value of N is 1 to about 4 or so).&lt;/p&gt;
&lt;p&gt;Here is a rundown of its use, from downloading books from archive.org to creating a baseline, and then comparing books.&lt;/p&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;p&gt;You should have &lt;a href=&quot;http://julialang.org/downloads/&quot;&gt;julia&lt;/a&gt; installed, and optionally ruby for the following downloading books step.&lt;/p&gt;
&lt;h3&gt;Downloading 19th Century Books&lt;/h3&gt;
&lt;p&gt;We have a convenient Ruby library that takes care of this part—see &lt;a href=&quot;https://github.com/wordtreefoundation/archdown&quot;&gt;archdown&lt;/a&gt;. If you have a working Ruby environment on your system, you should be able to install the gem and immediately begin fetching books:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;$ gem install archdown
$ archdown -y 1750-1850&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;It will create a ‘library’ folder with many 2-letter folders inside, and another set of 2-letter folders inside those. Each book will be downloaded to the folder corresponding to the first 2 and last 2 letters of its archive.org id. For instance, &lt;a href=&quot;https://archive.org/details/latewarbetween_00hunt&quot;&gt;latewarbetween_00hunt&lt;/a&gt; will download to &lt;code&gt;./library/la/nt/&lt;/code&gt;. The reason we do this is there are some archive.org id prefixes (e.g. &lt;em&gt;jstor&lt;/em&gt;) that have an abundant set of files associated with them, so we need a second level of folders.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; Downloading all books from 1750 to 1850 will probably take several days and 200 GB or so of space.&lt;/p&gt;
&lt;h3&gt;Creating a Baseline&lt;/h3&gt;
&lt;p&gt;The first thing to do once you have a lot of books is to create an ngram baseline. This is where we measure the “normal” frequency of each ngram in the English language during the period (i.e. the 19th century in our example).&lt;/p&gt;
&lt;p&gt;It’s important to create a baseline so that, later, when we find matches between books (during the comparison step below) we can weight the matches by importance—the more rare the ngrams are in English, the more “significant” the match.&lt;/p&gt;
&lt;p&gt;Let’s pick 100 books at random:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;find . -name &apos;*.txt&apos; | shuf -n 100 &gt; baseline-files.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;(&lt;em&gt;Note:&lt;/em&gt; &lt;code&gt;shuf&lt;/code&gt; is part of gnu core utils. On ubuntu, you can install it with &lt;code&gt;apt-get install coreutils&lt;/code&gt;; and on Mac OS, &lt;code&gt;brew install coreutils&lt;/code&gt;, but it will be called &lt;code&gt;gshuf&lt;/code&gt; instead.)&lt;/p&gt;
&lt;p&gt;Now, let’s create a baseline with N set to 3 (i.e. this will include phrases of one, two, and three words):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;julia baseline.jl -n 3 `cat baseline-files.txt` &gt; baseline.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Great! Now we have a baseline to feed the compare.jl script.&lt;/p&gt;
&lt;h3&gt;Comparing Books for Matching Ngrams&lt;/h3&gt;
&lt;p&gt;Let’s say we have a large text, &lt;code&gt;book1.txt&lt;/code&gt; and we want to compare it with another, &lt;code&gt;book2.txt&lt;/code&gt;. Here’s how:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;julia compare.jl -n 3 -b baseline.txt book1.txt X book2.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Using the baseline we calculated above, we’ll get some raw scores that might look something like this:&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;total_inv&lt;/th&gt;&lt;th&gt;total_mul&lt;/th&gt;&lt;th&gt;total_sqrt&lt;/th&gt;&lt;th&gt;sizex&lt;/th&gt;&lt;th&gt;sizey&lt;/th&gt;&lt;th&gt;namex&lt;/th&gt;&lt;th&gt;namey&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1.05526&lt;/td&gt;&lt;td&gt;14.26820&lt;/td&gt;&lt;td&gt;1.93123&lt;/td&gt;&lt;td&gt;5905&lt;/td&gt;&lt;td&gt;70627&lt;/td&gt;&lt;td&gt;book1.txt&lt;/td&gt;&lt;td&gt;book2.txt&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;We’ll talk more about what these results mean below.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;X&lt;/code&gt; between &lt;code&gt;book1.txt&lt;/code&gt; and &lt;code&gt;book2.txt&lt;/code&gt; in the command above is significant. This is a special marker that indicates all files &lt;em&gt;before&lt;/em&gt; the &lt;code&gt;X&lt;/code&gt; are to be matched against all files &lt;em&gt;after&lt;/em&gt; the X. In our simple example, we’re just comparing one book against another, but using this &lt;code&gt;X&lt;/code&gt; as a separator, it is also easy to compare all books in, say, “set A” to all books in “set B”. It might look like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;julia compare.jl -n 3 -b baseline.txt book1.txt book2.txt X bookA.txt bookB.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Which would compare all pairs, &lt;code&gt;book1 x bookA&lt;/code&gt;, &lt;code&gt;book1 x bookB&lt;/code&gt;, &lt;code&gt;book2 x bookA&lt;/code&gt;, and &lt;code&gt;book2 x bookB&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s say we want a little more detail—like the actual ngrams that matched between the two books, for instance. We can use the &lt;code&gt;-s&lt;/code&gt; switch which is short for &lt;code&gt;--show-matches&lt;/code&gt;. In addition, we can pair it with &lt;code&gt;-t&lt;/code&gt; to set the threshold score for word matches. In this case, let’s make the minimum word match score &lt;em&gt;0.01&lt;/em&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-language-bash&quot;&gt;&lt;code class=&quot;language-language-bash&quot;&gt;julia compare.jl -n 3 -b baseline.txt -v -s -t 0.01 book1.txt X book2.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;Now we get a lot more verbose output:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Using baseline: baseline.txt
Using files X: {&quot;book1.txt&quot;}
Using files Y: {&quot;book2.txt&quot;}
Measuring baseline size...
  87097 ngrams
elapsed time: 0.383290306 seconds (40527888 bytes allocated, 8.20% gc time)

Cross comparing...
Loading book1.txt...
Loading book2.txt...
Comparing... book1.txt x book2.txt&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;And there are individual ngrams listed with scores next to them:&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;th&gt;community situation&lt;/th&gt;&lt;td&gt;0.250&lt;/td&gt;&lt;td&gt;0.500&lt;/td&gt;&lt;td&gt;0.354&lt;/td&gt;&lt;td&gt;book1&lt;/td&gt;&lt;td&gt;book2&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;health positions&lt;/th&gt;&lt;td&gt;0.125&lt;/td&gt;&lt;td&gt;0.125&lt;/td&gt;&lt;td&gt;0.125&lt;/td&gt;&lt;td&gt;book1&lt;/td&gt;&lt;td&gt;book2&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th&gt;experienced nurse&lt;/th&gt;&lt;td&gt;0.083&lt;/td&gt;&lt;td&gt;0.167&lt;/td&gt;&lt;td&gt;0.118&lt;/td&gt;&lt;td&gt;book1&lt;/td&gt;&lt;td&gt;book2&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;h3&gt;Reading the Results&lt;/h3&gt;
&lt;p&gt;Let’s look again at the “total” scores we received as a summary of the strength of relatedness between book1 and book2:&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;total_inv&lt;/th&gt;&lt;th&gt;total_mul&lt;/th&gt;&lt;th&gt;total_sqrt&lt;/th&gt;&lt;th&gt;sizex&lt;/th&gt;&lt;th&gt;sizey&lt;/th&gt;&lt;th&gt;namex&lt;/th&gt;&lt;th&gt;namey&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1.05526&lt;/td&gt;&lt;td&gt;14.26820&lt;/td&gt;&lt;td&gt;1.93123&lt;/td&gt;&lt;td&gt;5905&lt;/td&gt;&lt;td&gt;70627&lt;/td&gt;&lt;td&gt;book1.txt&lt;/td&gt;&lt;td&gt;book2.txt&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;total_inv&lt;/strong&gt;: sum total of the inverse baseline frequency of all matching ngrams.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;total_mul&lt;/strong&gt;: like total_inv, but whereas the numerator in total_env is always 1.0, the numerator in &lt;strong&gt;total_mul&lt;/strong&gt; is the product of the count of occurrences of the ngram in document X, and the count of occurrences of the ngram in document Y.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;total_sqrt&lt;/strong&gt;: like total_mul, but the numerator is the square root of the product, instead of just the product.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sizex&lt;/strong&gt;: the total count of words in document X.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sizey&lt;/strong&gt;: the total count of words in document Y.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;namex&lt;/strong&gt;: the name of document X (filename).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;namey&lt;/strong&gt;: the name of document Y (filename).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Why break it down in this way? i.e. why not a single number representing the score? We’re still experimenting with the best formula to represent the relatedness between books. To normalize the score, the length of the books must be taken in to account somehow. We provide several “totals” so that we can experiment with different length-normalized scores. For instance, some possibilities:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;total_inv / (sizex + sizey)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;total_sqrt / sqrt(sizex**2 + sizey**2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If you copy the output of &lt;code&gt;compare.jl&lt;/code&gt; to a spreadsheet, each of these normalized scores and others can be easily experimented with.&lt;/p&gt;
&lt;p&gt;We’ve found that books with a wordcount smaller than 20k are not reliably scored using the ngram matching method. Because natural language is a constantly evolving target, people independently generate some language phrases that are, by random chance, the same as what others generate. Therefore, not all matches can be indicators of a certain relationship between books.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Presentation: The Late War & The Book of Mormon]]></title><description><![CDATA[Duane Johnson gave a presentation to the Salt Lake City PostMormon group summarizing some of the similarities between The Late War and the Book of Mormon, as well as further research made since the original work in 2014]]></description><link>http://blog.wordtree.org/articles/presentation-the-late-war-the-book-of-mormon</link><guid isPermaLink="false">http://blog.wordtree.org/articles/presentation-the-late-war-the-book-of-mormon</guid><pubDate>Wed, 28 Jan 2015 05:42:51 GMT</pubDate><content:encoded>&lt;p&gt;I gave a presentation to the Salt Lake City PostMormon group a couple of weeks ago summarizing some of the similarities between The Late War and the Book of Mormon, as well as further research we’ve made since our original work a little over a year ago.&lt;/p&gt;
&lt;p&gt;For the complete Comparison we published online, please see &lt;a href=&quot;http://wordtreefoundation.github.io/thelatewar/&quot;&gt;http://wordtreefoundation.github.io/thelatewar/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The sound quality improves a little way in to the presentation.&lt;/p&gt;
&lt;div&gt;
          &lt;div
            class=&quot;gatsby-resp-iframe-wrapper&quot;
            style=&quot;padding-bottom: 56.25%; position: relative; height: 0; overflow: hidden;margin-bottom: 1.0725rem&quot;
          &gt;
            &lt;iframe src=&quot;https://www.youtube.com/embed/BccPmfR5oSs&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen style=&quot;
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
          &quot;&gt;&lt;/iframe&gt;
          &lt;/div&gt;
          &lt;/div&gt;
&lt;p&gt;&lt;em&gt;Transcript Follows&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’m curious how many people have seen the presentation that we gave at the Ex-Mormon conference about a year and a half ago? About a third, ok. So this is meant to be a primer, as well as to go a little bit more in depth in what we’ve seen since then.&lt;/p&gt;
&lt;p&gt;So I want to explain a little bit about the motivation. The hypothesis—or at least the assumption—is, now that we know the Book of Mormon is a regular book, where did it come from? We think that some of what we’ve done shows evidence that could be further evidence that it’s a regular book, but we aren’t necessarily making the claim that this proves it’s all made up—it’s just more of a further exploration.&lt;/p&gt;
&lt;p&gt;My perspective on the Book of Mormon is kind of like—or the feeling I have is—it’s an old video game. Sometimes you want to go back and play the classics, bring it out for nostalgia. Sometimes you want to go a little bit further—you want to find out what’s the actual Maximum High Score on this game, can I take it all the way. That’s kind of what my brother, Chris, and I did.&lt;/p&gt;
&lt;p&gt;We’re using algorithms, and we put our geek on, and do some things to find out more information about this book. Because really, and I think many people share the same feeling here—you’re kind of growing throughout your life in Mormonism, and then when you leave, the growth doesn’t just stop, you want to keep growing. So this is part of my journey for growth.&lt;/p&gt;
&lt;p&gt;What’s really cool right now, is that the 19th century is being digitized. Everything that we know, everything that has been recorded, is being turned in to things that are searchable, indexable, computable. And it’s happening for free. That’s the starting point that we took when we began on this journey.&lt;/p&gt;
&lt;p&gt;Archive.org is amazing: millions of books are available for free, you just have to download them, and they don’t even have bandwidth caps, you can just keep downloading and downloading them. Google Books is similar—they’re a little bit more proprietary in the way that they’re doing it, some of their books aren’t available as free texts, but you can at least search the books. And we have all of these universities that are collecting data and just scanning, like this, bringing books into the digital domain.&lt;/p&gt;
&lt;p&gt;Chris’s original talk was, “How the Book of Mormon Destroyed Mormonism,” and what he means—and I’d like to put the context around that—what he means is that questions that can be turned into an algorithm are being coupled with knowledge that can be represented as data, and when the two collide, you get answers that have never been known before. Our ability to do these kinds of things is increasing exponentially—so even if The Late War is totally a wrong hypothesis (and I think we’re still on to something), even if it’s totally fake, we’re still going to be able to continue pursuing new answers and new frontiers in Book of Mormon research that was never possible before.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-4b791.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 960px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 74.77611940298507%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAABYlAAAWJQFJUiTwAAADIElEQVQoz22SyU8TYRjGpwtYmKXtrN0tVkm8eHOLkuh/4MWbnpFCEZSyWSoUMC4Hl6sHL55coiSaEI1eQQWEMtN22k5XaOlCW6ZDwbrUbzAYD05+eeb75nufed7k/aDlQDQYTchE4pF4OhxLCYn1RCqTSGWFeDq5thFPrieSmVhqnReSHC+wvFzPheNLbAQCr3BijQsJc1+WltnQ/OfFAC8Ew4KfDfrZUJCPLq2wSyvcsj8AmF/4OvdpkQ1Gw/H0akiAQkIyHEtHYmvRxFo8meHBX0MRNsD7VwNcIMxxPMvxqxy/8NXPgd6S66AYdLcXHgPmVCZXrFRrUu3bbv2XVKuXy1K+WNkolIolESwKxUqpXM3lNgslcaf+q7b7c2u7XqnuprIFKJMvzszOTd97fPveA9/UnfGJKd/kLd/ktG9qWtbJae/ElGd8UtabPo93fGzs5ph3wj008uzla6i2Uxu99RQ1d8AoqVQ1Q3sPrFYe1cEOrOUQqjG3NJMH1PQBNVC1QgFOVSoV0Kt916CqVJ24P2M7dpExteGkQafHERSj9LoOh+203XLKbj7TZj17yHrKbjnvsB2kiJZWWKfVKpWKweFRaCObHbk74zhxyWQ7QjImPUEgKNyKwBq4VQbZY3/RisIwCmM6TKGEhkZuQLl8zvtw9vDJy4y1DadpgiFxmiBoAqdwLY6hOgTVof+AIDpES2iVTYqRGx7ZPP7onfXYBYIxYrj+bx2iBRHwf8H0mEINDQNzvpD33H/LtJ+jDCRII/7E0gTJ4CRDUkaKMtL0PoyJoQwUbabVGtWwxwMVSyXfozeW9uMmC2OwGClgYHDGAPogabAzyQajxWCyGCw2s9VutTvsjnYHCB/1eqEfPxue20/k8SBqTKvBtC0AGNVo4GZVE5idEqhCJU8IUuyxP6r+ATckSrX3Hz4ODrgGrrvcA/39fb391/qczi6n80pPT7fL5ert7XV2O7u6ujo7O7u7ne5B99DwEKh7/uIVFE2kK2IV3M1coVSuiJublS1xe2urKorbfwBnoihJ0k65Aj5KjUYDNFv/3sgWy78BeG6TeIQ629UAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;110k books&quot;
        title=&quot;&quot;
        src=&quot;/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-c83f1.png&quot;
        srcset=&quot;/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-569e3.png 240w,
/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-93400.png 480w,
/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-c83f1.png 960w,
/static/110k_books-b241267f6c5d64057b1bacfa12a65c3b-4b791.png 1340w&quot;
        sizes=&quot;(max-width: 960px) 100vw, 960px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;This was our original study in 2013, we analyzed 110,000 books. Each of these blue dots, which you can barely see here, is a book. And what we have here is the number of words in the book. And then over here what we have is how many rare phrases matched with the Book of Mormon—and they were non-biblical. So what that means is we were ignoring things like, “And it came to pass” because that’s a very common phrase—that doesn’t actually uniquely match the Book of Mormon with anything else, because there are lots of books like that. But if you find something like “title of liberty,” or something like that, that’s much more rare, so you want to be able to weight those and increase the significance of those matches.&lt;/p&gt;
&lt;p&gt;So what we found here—I think many people have seen this, if not, I’ll just briefly go over this—anything that perfectly matches the book of mormon would basically be this line, it would be all the way down. So you can see the Book of Abraham is a pretty close match, the First Book of Napoleon is a pretty good match; Book of Moses—holy cow, it’s pretty strange how Moses speaks like Joseph Smith—we also have The Late War, and The Book of Commandments over there, which is very similar. So those are the matches.&lt;/p&gt;
&lt;p&gt;And this is The Late War. I’m just going to hand this around. This is a 200 year old book, so please treat it nicely. Feel free to open it, but don’t crack it open all the way. I’m just going to pass it around and you can take a look at it. It was a very common book—Rick Grunder, this is from his personal collection—he has six of them. So it wasn’t a particularly difficult to find book in the early 1800s—it was published in 1816. It was about the War of 1812.&lt;/p&gt;
&lt;p&gt;I kind of really like this, because on my journey I’ve always wondered, why the heck does God want to talk about war all the time—it’s just kind of like, I want more spiritual stuff—that’s the way I was thinking, and we’d just sort of slog through Alma and stuff. We think that this matches significantly.&lt;/p&gt;
&lt;p&gt;Here are some of the matches. I’m curious how many of you have seen this already? Again, about a third, maybe a little less. So these are some of the matches for The Late War and the Book of Mormon.&lt;/p&gt;
&lt;table width=&quot;80%&quot; align=&quot;center&quot; class=&quot;comparison&quot;&gt;
    &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;The Late War&lt;/th&gt;&lt;th&gt;Book of Mormon&lt;/th&gt;&lt;/tr&gt;
    &lt;tr&gt;
      &lt;td width=&quot;10%&quot;&gt;26:1&lt;/td&gt;
      &lt;td&gt;&lt;b&gt;the fourth day of&lt;/b&gt; the &lt;b class=&quot;c1&quot;&gt;seventh month&lt;/b&gt;, &lt;b class=&quot;c2&quot;&gt;which is&lt;/b&gt; the birth day of Columbian Liberty and Independence,&lt;/td&gt;
      &lt;td&gt;&lt;b&gt;the fourth day of&lt;/b&gt; this &lt;b class=&quot;c1&quot;&gt;seventh month&lt;/b&gt;, &lt;b class=&quot;c2&quot;&gt;which is&lt;/b&gt; in the tenth year of the reign of the judges.&lt;/td&gt;
      &lt;td width=&quot;10%&quot;&gt;Alma 10:6&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Both referring to periods of time when we switched from the rule of Kings to rule by vote—the rule of the people. The latter in the Book of Mormon isn’t necessarily claiming that it’s the first day, it’s just related. It goes along with our hypothesis that maybe Joseph Smith read this book, and then some things were kind of ruminating, he had some ideas, and then he kind of remixed it, and he had a cool story.&lt;/p&gt;
&lt;p&gt;Over here, near Moravian Town. Some LDS apologists have claimed that Moravian Town was not known until 1912 and so it was ridiculous for Joseph Smith to have known about that, and so how could he have made Morianton from that town. But here we have Moravian Town and Tecumseh in the same sequence as The Book of Mormon.&lt;/p&gt;
&lt;p&gt;Here we have “two thousand hardy men, who fought freely for their country,” they were “men of dauntless courage.” Here we have “two thousand … young men” they were “valiant for courage.”&lt;/p&gt;
&lt;p&gt;This is one of my favorites. If you think about Joseph Smith in his time, they just came to this—it’s basically the equivalent of us going to Mars, right? People just moved over to this New World, it’s totally fascinating, they don’t know what to think of it—of course in the 1400s even moreso—but they’re still exploring what this land is about. So they’re still interested in explaining it to people. It’s “plentiful,” this land has “gold and silver,” and “all manner of creatures that are used for food” (and in the Book of Mormon, they happened to be European creatures) but they also have the “mammoth” and the “elephant”, which is an interesting idea. So, the elephant is not claimed to be in North America in The Late War, but it is in the Book of Mormon, which is an interesting connection. And also, we have cureloms and cumoms—I forget who it was, one of Joseph Smith’s associates [Orson Pratt], claimed it was a mammoth. Interesting parallels there.&lt;/p&gt;
&lt;p&gt;So here we have, “weapons of war,” “great slaughter,” “ditches surrounded”… so these are descriptions of battles, and in this particular case, it’s centered around a fort, and it describes the same things in the same sequence. Here is digging trenches around these forts. So in the War of 1812, it was common practice, I mean they were building trenches to defend themselves from the British. This was military knowledge—this is what they were doing to prevent attacks.&lt;/p&gt;
&lt;p&gt;So, there are many more here. I’m not sure how many I want to go over individually, but I just want to give context for how many rare matches there are in these two books. Very interesting. For me personally, another favorite that I have is the Liahona. It’s not for certain that this is an exact match—but if it is a match, it sure is cool—because in The Late War, this “ball of curious workmanship” was a torpedo—it was basically the very beginning of timed warfare on the seas—so they would toss them out, and with a clock, blow it up at the right time, and it would destroy a ship. So we see here that we have “clock” and “spindles” and it’s made out of “brass”, “curious workmanship”. I’ve always wondered, you know, why did God put that little ball next to the tent—why was it curious, and what was this thing? I always remember thinking, “what if we could go and get that technology? It would be so amazing! Because God made it!” So that’s one of the things I think is cool.&lt;/p&gt;
&lt;p&gt;This one, I’m going to go into further detail with, but this one is really amazing. And then, here we go, “borders of the land of Zarahemla”, “borders of the land Columbia”, they “gathered together,” all these phrases are very similar. “Chief warriors” and “chief captains” laying their weapons “at the feet of” some special military leader. “People to rise up” one against another, their own families. “go with all our might against” a city. And this is the longest match that we found:&lt;/p&gt;
&lt;table align=&quot;center&quot; class=&quot;comparison&quot;&gt;
  &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;/th&gt;&lt;th&gt;The Late War&lt;/th&gt;&lt;th&gt;Book of Mormon&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;10%&quot;&gt;34:10&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;it came to pass&lt;/b&gt;, &lt;b class=&quot;c1&quot;&gt;in the same year&lt;/b&gt;, &lt;b class=&quot;c2&quot;&gt;that the people of &lt;i&gt;Columbia&lt;/i&gt;&lt;/b&gt; were revenged of the evil:&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;it came to pass&lt;/b&gt; that &lt;b class=&quot;c1&quot;&gt;in the same year&lt;/b&gt; &lt;b class=&quot;c2&quot;&gt;that the people of &lt;i&gt;Nephi&lt;/i&gt;&lt;/b&gt; had peace restored unto them,&lt;/td&gt;
    &lt;td width=&quot;10%&quot;&gt;Alma 50:37&lt;/td&gt;
  &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;These are all coming from &lt;a href=&quot;http://wordtreefoundation.github.io/thelatewar/&quot;&gt;http://wordtreefoundation.github.io/thelatewar/&lt;/a&gt; so if you want to visit that, it goes into detail on all of those. Some people wonder, how much of the phrases are you skipping with the ellipses? Sometimes it’s a lot, sometimes it’s a little, so it is interesting to look at that more.&lt;/p&gt;
&lt;p&gt;So here’s one of them that I really like: the river battle. In The Late War, we have a battle raging “with great violence, and the men of Britain strove hard to pass over the river called Saranac” and I remember reading the Book of Mormon and thinking, is it a river? or is it waters? that’s weird. I always wondered, why are we describing it in two different ways? Well, here we have a parallel: it’s “the river called Saranac”, and they’re on “opposite side of the water”, they “slew them with great slaughter”, and they drove them back from crossing the bridges, and they were “slain”, “so that the waters of the Saranac were dyed with the blood of the servants of the king.” So all of the people went in to the river. And basically with the same language [in the Book of Mormon]: here we have “the guards of the king” instead of the “servants of the king”, who “slew” them, drove them back and cleared the ground on “the west side” of the river instead of the “opposite side” of “the river Sidon”, “throwing bodies of the Lamanites which had been slain, into the waters of Sidon, that thereby his people might have room to cross.” Another thing that’s kind of weird to me—it’s kind of implicit here, but why did they need room to cross? It’s a river, right? It’s miles and miles, why can’t you just kind of go around the people on the other side of the bank? Maybe there was a bridge? I don’t know. Maybe some mental imagery prevented the author from thinking in terms of a wide river there.&lt;/p&gt;
&lt;p&gt;Here’s another one. This is a tower speech. This is nearing the end of the War of 1812. I don’t know the exact month, but in The Late War, we have this man—Willet—who was giving a speech. He gets up on a podium (here we have the word, “rostrum”) and talks to the people, gathered around—30,000 of them, gather around, and they “pitch their tents” from “the surrounding country” and they “assembled together” and they “gather themselves together” and this is a very old man, he’s in his seventies, and “the people shouted with a loud voice,” because of liberty and their country. He says that he’s very old, and his “bodily infirmities”—if he didn’t have these, he would keep fighting for his country. The same sort of things happen in Mosiah, for King Benjamin—“it came to pass that … the people gathered themselves together throughout all the land, And … they pitched their tents round about, every man according to hsi family … for the multitude [was] great … he caused a tower to be erected, that thereby his people might hear the words which he should speak … [he caused them to] assemble yourselves together” and he is “about to go down to [his] grave.” So we don’t have those same words, but we have “bodily infirmities”, “aged Willet”, so there are some parallels but not exact words; and “they all cried with one voice,” so I think it’s interesting that there’s this same dynamic between this person and the crowd, and they describe it in the same way.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/hebraisms2-99c7c9a3f247a59c03f87a5392d96aaf-00f86.jpg&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 800px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 74.625%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAQAF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAddkJk//xAAVEAEBAAAAAAAAAAAAAAAAAAAQAf/aAAgBAQABBQJj/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGBAAAwEBAAAAAAAAAAAAAAAAAAEhETH/2gAIAQEAAT8hVUMGiDhp/9oADAMBAAIAAwAAABCw/wD/xAAVEQEBAAAAAAAAAAAAAAAAAAAQIf/aAAgBAwEBPxCH/8QAFREBAQAAAAAAAAAAAAAAAAAAECH/2gAIAQIBAT8Qp//EABsQAQADAQADAAAAAAAAAAAAAAEAESExUYGh/9oACAEBAAE/EAVL3C/F75msqQdhVter9jrZ/9k=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;hebraisms2&quot;
        title=&quot;&quot;
        src=&quot;/static/hebraisms2-99c7c9a3f247a59c03f87a5392d96aaf-00f86.jpg&quot;
        srcset=&quot;/static/hebraisms2-99c7c9a3f247a59c03f87a5392d96aaf-6a66e.jpg 240w,
/static/hebraisms2-99c7c9a3f247a59c03f87a5392d96aaf-bc76f.jpg 480w,
/static/hebraisms2-99c7c9a3f247a59c03f87a5392d96aaf-00f86.jpg 800w&quot;
        sizes=&quot;(max-width: 800px) 100vw, 800px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;So that’s it for parallels right now. The strongest argument that The Late War has is that “Hebraisms” in the Book of Mormon, don’t really offer evidence for it being ancient, because all of these “Hebraisms” are also found in The Late War. Chiasmus, Cognate Accusative, Negative Questions, Construct State… Rick Grunder has put together an analysis of almost all of these (I added a few from other sources) and described what they are. I kind of feel bad a little bit, because I know there are some linguists who are defending the Book of Mormon, and they have some really awesome knowledge from their domain, and they’ve put it in to defending the Book of Mormon, but they just didn’t look around enough to see the context. So really, that’s not good evidence.&lt;/p&gt;
&lt;p&gt;So this is the method that we used. I want to just describe this briefly. It’s fairly simple math, so I’ll just go over it briefly. This is how we score a document: in this case we’re looking at bigrams, so that means “two words,” so we take a two-word sequence like “I Nephi” and we say “how many times does ‘I Nephi’ appear in 100,000 documents, or 50,000 documents?” And here’s [the number one for] once, i.e. in the Book of Mormon. If we were to find something that said “I Nephi,” it would be a super-mega-match, it would be like “Holy Cow! We found something awesome!” but we didn’t—there are no “I Nephis” anywhere else. “Nephi, having” same thing, but “having been” shows up in a lot of documents. So 10,000. “been born”, a little rarer than this, but not terribly rare. Same with “born of”. But “of goodly” turns out to be somewhat rare, and “goodly parents” turns out to be quite rare—as rare as “I Nephi” in our dataset. So we take the inverse of each of them, and we get 3.04. So as you can see here, the score for this document—basically what we’re doing here is scoring “how many rare words there are”—it’s not very useful yet. That score is 3 because “I Nephi”, “Nephi having” and “goodly parents” are rare. The rest of them are almost insignificant.&lt;/p&gt;
&lt;p&gt;What we want to do is find the matching rare words, right? So here’s something I found: Jonathan Swift says, “My birth was of the lower sort, having been born of plain and honest parents.” What we want to do is see what’s the score, or what’s the match—how valuable is this match—in assessing whether there’s a connection between these two. There’s no “I Nephi” in there—that would be awesome if we did, we didn’t find it, so it doesn’t count. But, “having been” is there, so that shows up here; “been born” is here; “born of” shows up, and “parents” shows up. So, we add up all those numbers, we get 0.005. So this is not a significant find.&lt;/p&gt;
&lt;p&gt;I guess I should explain a little bit more. What we did in the study is we found significant finds, right? We found words that are rare. Phrases of 4 or more matches that match other documents and were not found anywhere else. So those are what we mean by rare matches.&lt;/p&gt;
&lt;p&gt;Q: How high does the number have to be for you to consider it significant?&lt;/p&gt;
&lt;p&gt;A: In our original study, if it was found in 5 or more documents, then it wasn’t really significant to us. I guess that’s not entirely true—it’s just the math, right? If it shows up in one other document, then it’s rare—it’s going to be a “one over two”, so the “two” would be the Book of Mormon and one other book.&lt;/p&gt;
&lt;p&gt;Q: So a point five would be significant?&lt;/p&gt;
&lt;p&gt;A: Yeah, that would definitely be. It’s not like each individual match is significant, but when you add up signficant ones like that, then you get a higher score, and that’s what happened with The Late War and The First Book of Napoleon.&lt;/p&gt;
&lt;p&gt;So, continuing on. That’s basically our first study. What we found though, is kind of interesting. The Late War is one book in a genre. It’s something that’s been studied by Eran Shalev—he wrote a book called American Zion—and he’s a professor (non-LDS) at the history department at Haifa, Israel. He studied American texts that were written like the bible, and The Late War falls in this genre. So does the Book of Mormon. This whole genre is really an interesting genre, because it tells us a lot about the early American ideas that were happening. There were a couple of things happening—one was America was reading a book that it considered Holy, that had nothing to do with them—like, Israel, the Holy Land, is far away. The promised land, the chosen people—all of this stuff is really nothing to do with them. But they’re forming an identity, right? They’re America. They’re trying to create a story about themselves, and they cherish this book, so they created stories around the bible that related to America. They basically biblicized themselves—they created a story about how they are biblical. And you’ll get tons of stories about how America &lt;em&gt;is&lt;/em&gt; the Chosen Land, that they are the chosen people, and they’ll talk about the similarities between the Exodus and themselves leaving Britain. So the Book of Mormon in that sense is not unique at all—it was very much a part of this zeitgeist.&lt;/p&gt;
&lt;p&gt;So these are some of the books that we’ve since discovered and we’ve actually turned them into digital documents. These are a little bit harder to find, that’s why we didn’t have them in our original study. Many of them didn’t exist in archive.org’s stuff, and many of them, if they did at all, were very messy. When you do OCR, scans of documents, they end up with mistakes and it’s usually only about an 80% accuracy rate. And so it takes a lot of manual work to get these going. So this is the new set, and we could definitely use help in finding, identifying, or improving the scope and quality of documents that we have. We’ve made them publicly available here, so anyone can download them, study them, compute with them. Many of them are quite small. Our algorithm doesn’t really work with small texts. The problem with small texts is that the uncertainty increases. So if we find a match in a small text, it could mean something, but it also really might not mean something. Since that’s the case, we’ve had to prune the ones that aren’t very big.&lt;/p&gt;
&lt;p&gt;So this is a preliminary result. We kind of wanted to look at the set of documents we have now, and what are the relationships that we see in them? The size of the circles is the size of the books. The width of the line is the relative strength of the connection. So you can see that The Late War was definitely inspired by The American Revolution which was written 14 years before. But the other ones, it’s not as clear. There are a lot of similar numbers. It’s not really clear yet, from this particular algorithm, if there’s a really strong connection. We do have some exciting things that are coming, but we don’t really have results to share right now. One of the things that we’ve really wanted to do, and that we’ve found a method to do, is studying synonyms. If you look at sentences and find similar words in the same sequence, if you find long matches of sequences, that’s also a very strong signal. We couldn’t do that with this study, because our ability to tell what was synonymous was limited. But there’s been some really cool research in vectorization of words, so you can take a word and translate it into a large dimensional space, and relate their meanings to one another now. It’s all open source, and it’s all available, so we’re going to do that next.&lt;/p&gt;
&lt;p&gt;We have a little group—WordTree Foundation—we have a google group and a github account, where we contribute code and things like that. If any of you are interested, there are lots of interesting things to be done. We aren’t particularly—we’re kind of a loose-knit group, so it’s not like “if you join us you have to go do this.” It’s more of, “What’s your interest?” Maybe we have resources. Maybe someone is interested and they can do it with you. It’s a collective. We have about 20 members right now. So that’s what we’re doing next, and that’s where we are so far. Thank you.&lt;/p&gt;
&lt;p&gt;[Q&amp;#x26;A]&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Understanding ARPA and Language Models]]></title><description><![CDATA[I started off today thinking I’d be able to transform a previous n-gram library we wrote in the Julia programming language over to KenLM, a very fast Language Model generator. Instead, I ended up spending most of the day learning about language models and data formats. I thought I’d pass along some of this information and any insights I’ve had.]]></description><link>http://blog.wordtree.org/articles/arpa-lm</link><guid isPermaLink="false">http://blog.wordtree.org/articles/arpa-lm</guid><pubDate>Sat, 11 Jan 2014 19:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Language Models are a better way of comparing phrase probabilities than n-gram frequencies.&lt;/p&gt;
&lt;p&gt;At the WordTree Foundation, we’re exploring ways of mapping the similarities and influences among various books, with the Book of Mormon of special interest in this exploration. In the past, we’ve shown raw unconditional probabilities to be an interesting (albeit limited) way of scoring similarities among books. Our online publication of &lt;a href=&quot;http://wordtreefoundation.github.io/thelatewar/&quot;&gt;A Comparison of The Book of Mormon and The Late War&lt;/a&gt; was the result of that original research.&lt;/p&gt;
&lt;p&gt;I started off today thinking I’d be able to transform the &lt;a href=&quot;https://github.com/canadaduane/TextGrams.jl&quot;&gt;previous n-gram library&lt;/a&gt; we wrote in the Julia programming language over to KenLM, a very fast Language Model generator. Instead, I ended up spending most of the day learning about language models and data formats. I thought I’d pass along some of this information and any insights I’ve had.&lt;/p&gt;
&lt;p&gt;First, a Language Model is far better than the pure N-gram (unconditional) probabilities we’ve been using at the WordTree Foundation up to this point. In particular, language models have a notion of &lt;em&gt;conditional probability&lt;/em&gt; which makes assessing probabilities of word occurrences in a text more accurate.&lt;/p&gt;
&lt;p&gt;When I take a text like the Book of Mormon and pass it through &lt;a href=&quot;https://kheafield.com/code/kenlm/&quot;&gt;KenLM&lt;/a&gt;’s “lmplz” processor, it generates a file called an ARPA file. The ARPA file format looks like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot;&gt;
      &lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;\data\
ngram 1=5776
ngram 2=55566

\1-grams:
-4.7039757 &lt;unk&gt; 0
0 &lt;s&gt; -1.505814
-4.554822 &lt;/s&gt; 0
-1.7441652 the -1.075229
-2.4278247 book -1.6445116
-1.6198214 of -1.2298658
-3.932976 mormon -0.52456135
-1.452003 . -4.009832
-2.7216232 an -0.6389431
-3.7242882 account -0.75844955
…

\2-grams:
-0.000042455064 . &lt;/s&gt;
-1.9652246 &lt;s&gt; the
-0.5145896 of the
-1.5662498 mormon the
-1.7051648 written the
-0.30002946 by the
-1.6727574 hand the
-0.429893 upon the
-2.2684872 plates the
-1.6545775 taken the
-0.3712691 from the
…

\end\&lt;/code&gt;&lt;/pre&gt;
      &lt;/div&gt;
&lt;p&gt;It wasn’t obvious to me at first what these negative numbers were. It turns out they are &lt;em&gt;log probabilities&lt;/em&gt; in base 10. In other words, rather than saying “the chance of seeing ‘the’ is 0.018023”, the ARPA format uses &lt;code&gt;-1.7441652&lt;/code&gt; which means take “10” and raise it to the power of “-1.7441652” to get the probability (i.e. 0.018023). This form of representation for probabilities is usually more compact because probabilities can get very small (e.g. rather than writing “0.000000478630092” we can just write &lt;code&gt;-6.32&lt;/code&gt;). In addition, as a &lt;em&gt;log&lt;/em&gt; value, they naturally represent order of magnitude more prominently.&lt;/p&gt;
&lt;p&gt;In an ARPA file, the unigrams (1-grams) are &lt;em&gt;unconditional probabilities&lt;/em&gt; while the N-grams with N of 2 or larger are &lt;em&gt;conditional probabilities&lt;/em&gt;. In other words, when we see “-1.7441652 the” in the 1-grams section, it is simply the log probability that the word &lt;code&gt;the&lt;/code&gt; will show up in the language, i.e. in mathematical notation, &lt;strong&gt;P&lt;/strong&gt;(&lt;em&gt;the&lt;/em&gt;), or “Probability of &lt;code&gt;the&lt;/code&gt;”. But in the 2-grams section, when we see “-0.5145896 of the”, this is the probability that &lt;code&gt;the&lt;/code&gt; will show up after &lt;code&gt;of&lt;/code&gt;, i.e. in mathematical notation, &lt;strong&gt;P&lt;/strong&gt;(&lt;em&gt;the&lt;/em&gt;|&lt;em&gt;of&lt;/em&gt;), or “Probability of &lt;code&gt;the&lt;/code&gt; given &lt;code&gt;of&lt;/code&gt;”.&lt;/p&gt;
&lt;p&gt;There are three “special” words in a language model: &lt;strong&gt;&amp;#x3C;s&gt;&lt;/strong&gt;, &lt;strong&gt;&amp;#x3C;/s&gt;&lt;/strong&gt;, and &lt;strong&gt;&amp;#x3C;unk&gt;&lt;/strong&gt;. The &lt;strong&gt;&amp;#x3C;s&gt;&lt;/strong&gt; denotes the beginning of a sentence, and the &lt;strong&gt;&amp;#x3C;/s&gt;&lt;/strong&gt; denotes the end of a sentence. This differs from our original study where we had no concept of beginnings and ends of sentences—we just ignored sentence boundaries. The &lt;strong&gt;&amp;#x3C;unk&gt;&lt;/strong&gt; special word means “unknown” and is used in the language model to represent the probability of a word not in the model (I believe this is also known as “out of vocabulary” or OOV).&lt;/p&gt;
&lt;p&gt;By using conditional probabilities, queries for phrases will result in probabilities that more accurately reflect the frequency or rarity of that phrase. Ultimately, this will lead to a more accurate scoring algorithm when comparing books and trying to uncover non-obvious relationships or influences among texts.&lt;/p&gt;</content:encoded></item></channel></rss>